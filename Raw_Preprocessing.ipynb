{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T15:55:39.001578Z",
     "start_time": "2024-04-26T15:55:38.997858Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %pip install tqdm\n",
    "# %pip install pyedflib\n",
    "\n",
    "import pyedflib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import torch\n",
    "import pyedflib\n",
    "import scipy.signal as signal\n",
    "import h5py\n",
    "from scipy import signal, interpolate\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba8f0ff57e78e723",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T15:55:39.005510Z",
     "start_time": "2024-04-26T15:55:39.003057Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.style.use('bmh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f1e69ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8396a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EKG', 'EOG-L', 'EOG-R', 'EMG', 'EEG1', 'EEG2', 'EEG3', 'Pres', 'Flow', 'Snore', 'Thor', 'Abdo', 'Leg', 'Therm', 'Pos', 'EKG_Off', 'EOG-L_Off', 'EOG-R_Off', 'EMG_Off', 'EEG1_Off', 'EEG2_Off', 'EEG3_Off', 'Pleth', 'OxStatus', 'SpO2', 'HR', 'DHR']\n"
     ]
    }
   ],
   "source": [
    "# Print out annotations of signals in EDF file\n",
    "def edf_signal_labels(edf_file_path):\n",
    "    signal_file = pyedflib.EdfReader(edf_file_path)\n",
    "    signal_labels = signal_file.getSignalLabels()\n",
    "    signal_file._close()\n",
    "\n",
    "    return signal_labels\n",
    "\n",
    "\n",
    "signal_labels_0001 = edf_signal_labels('/run/media/u2212061/DISK_YUAN/CS913/mesa/polysomnography/edfs/mesa-sleep-0001.edf')\n",
    "\n",
    "print(signal_labels_0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b93c39e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256.0\n"
     ]
    }
   ],
   "source": [
    "# Original frequency of PPG signal\n",
    "\n",
    "def original_frequency(edf_file_path, signal_labels):\n",
    "    signal_file = pyedflib.EdfReader(edf_file_path)\n",
    "    signal_index = signal_labels.index('Pleth')\n",
    "    sampling_rate = signal_file.getSampleFrequency(signal_index)\n",
    "\n",
    "    signal_file._close()\n",
    "\n",
    "    return sampling_rate\n",
    "\n",
    "\n",
    "ppg_original_rate_0001 = original_frequency('/run/media/u2212061/DISK_YUAN/CS913/mesa/polysomnography/edfs/mesa-sleep-0001.edf', signal_labels_0001)\n",
    "\n",
    "print(ppg_original_rate_0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e21ec462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Low-pass filtering removes high-frequency noise and prevents aliasing during down-sampling.\n",
    "# We specifically used a low-pass filter as we wished to keep lower frequency components such as breathing and capillary modulation intact.\n",
    "# A zero-phase 8th order low-pass Chebyshev Type II filter with a cutoff frequency of 8Hz and a stop-band attenuation of 40dB.\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.cheby2.html\n",
    "\n",
    "def lowpass_filter(ppg_signal, original_freq, cutoff_freq=8, stopband_attenuation=40):\n",
    "    # Wn\n",
    "    nyquist_freq = original_freq * 0.5\n",
    "    normalized_cutoff = cutoff_freq / nyquist_freq\n",
    "\n",
    "    # cheby2 (second-order section)\n",
    "    sos = signal.cheby2(N=8, rs=stopband_attenuation, Wn=normalized_cutoff, btype='lowpass', output='sos')\n",
    "    filtered_signal = signal.sosfilt(sos, ppg_signal)\n",
    "\n",
    "    return filtered_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "608f5611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Downsampling\n",
    "# The filtered PPG was downsampled to 34.13Hz using linear interpolation, reducing the computational and memory requirements for ML.\n",
    "# We choose a sampling rate of 34.13Hz as this resulted in 1024 (2^10) samples per 30s sleep-window. \n",
    "# By using a 2^n number we could maintain full temporal alignment of data with sleep-windows during ML pooling operations.\n",
    "\n",
    "def downsample_signal(filtered_signal, original_freq, target_freq=34.13):\n",
    "    original_time = np.arange(len(filtered_signal)) / original_freq\n",
    "    new_time = np.arange(0, original_time[-1], 1/target_freq)\n",
    "    f = interpolate.interp1d(original_time, filtered_signal, kind='linear')\n",
    "    downsampled_ppg = f(new_time)\n",
    "\n",
    "    return downsampled_ppg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62b7ce6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Clean and standardize signals\n",
    "# WAVPPG was cleaned by clipping values to three standard deviations and then standardized by subtracting the mean and dividing by the standard deviation.\n",
    "# Normal distribution\n",
    "\n",
    "def clean_and_standardize(downsampled_signal):\n",
    "    mean = np.mean(downsampled_signal)\n",
    "    std = np.std(downsampled_signal)\n",
    "    \n",
    "    clipped_signal = np.clip(downsampled_signal, mean - 3 * std, mean + 3 * std)\n",
    "    \n",
    "    standardized_signal = (clipped_signal - mean) / std\n",
    "\n",
    "    return standardized_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2ced3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_ppg(ppg, original_fs=256):\n",
    "    nyq = 0.5 * original_fs\n",
    "    cutoff = 8 / nyq\n",
    "    b, a = signal.cheb2ord(cutoff, cutoff + 0.1, 3, 40)\n",
    "    sos = signal.cheby2(b, 40, cutoff, btype='lowpass', output='sos')\n",
    "    filtered_ppg = signal.sosfiltfilt(sos, ppg)\n",
    "\n",
    "    target_fs = 34.13\n",
    "    original_time = np.arange(len(filtered_ppg)) / original_fs\n",
    "    new_time = np.arange(0, original_time[-1], 1/target_fs)\n",
    "    f = interpolate.interp1d(original_time, filtered_ppg, kind='linear')\n",
    "    downsampled_ppg = f(new_time)\n",
    "\n",
    "    mean = np.mean(downsampled_ppg)\n",
    "    std = np.std(downsampled_ppg)\n",
    "    clipped_ppg = np.clip(downsampled_ppg, mean - 3*std, mean + 3*std)\n",
    "\n",
    "    wavppg = (clipped_ppg - np.mean(clipped_ppg)) / np.std(clipped_ppg)\n",
    "\n",
    "    return wavppg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cbb1d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolation(segment, original_fs=256, target_fs=34.13):\n",
    "    time_old = np.arange(len(segment)) / original_fs\n",
    "    time_new = np.arange(0, time_old[-1], 1/target_fs)\n",
    "    f = interpolate.interp1d(time_old, segment, kind='quadratic', bounds_error=False, fill_value='extrapolate')\n",
    "    segment = f(time_new)\n",
    "\n",
    "    return segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d210175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "def find_edf_files(input_dir, output_dir):\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    edf_file_names = []\n",
    "\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith('.edf'):\n",
    "            edf_file_names.append(filename)\n",
    "    \n",
    "    return edf_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ac11939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ppg_from_edf(edf_file_path, signal_label='Pleth'):\n",
    "    f = pyedflib.EdfReader(edf_file_path)\n",
    "    signal_labels = f.getSignalLabels()\n",
    "    signal_index = signal_labels.index(signal_label)\n",
    "    ppg_signal = f.readSignal(signal_index)\n",
    "    original_frequency = f.getSampleFrequency(signal_index)\n",
    "    f._close()\n",
    "\n",
    "    return ppg_signal, original_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b1d7a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_edf_to_txt_no_header(input_dir, output_dir):\n",
    "    edf_file_names = find_edf_files(input_dir, output_dir)\n",
    "    for name in tqdm(edf_file_names, desc='Converting EDF to TXT'):\n",
    "        basename = name.split('.')[0] \n",
    "        try:\n",
    "            path = os.path.join(input_dir, name)\n",
    "            ppg_signal, original_freq = read_ppg_from_edf(path)\n",
    "            # downsampled_signal = downsample_signal(ppg_signal, original_freq)\n",
    "            interpolated_signal = interpolation(ppg_signal)\n",
    "            \n",
    "            df = pd.DataFrame(interpolated_signal) \n",
    "            \n",
    "            output_file = os.path.join(output_dir, f'{basename}.txt')\n",
    "            df.to_csv(output_file, index=False, sep='\\t', header=None)\n",
    "            # print(f'File {basename} converted successfully.')\n",
    "        except Exception as e:\n",
    "            print(f'Error converting file {basename}: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f7cc318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_edf_to_txt(input_dir, output_dir):\n",
    "    \n",
    "    edf_file_names = find_edf_files(input_dir, output_dir)\n",
    "\n",
    "    for name in tqdm(edf_file_names, desc='Converting EDF to TXT'):\n",
    "        basename = name.split('.')[0]\n",
    "        try:\n",
    "            path = os.path.join(input_dir, name)\n",
    "            ppg_signal, original_freq = read_ppg_from_edf(path)\n",
    "            # filtered_signal = lowpass_filter(ppg_signal, original_freq)\n",
    "            # downsampled_signal = downsample_signal(filtered_signal, original_freq)\n",
    "            # downsampled_signal, downsampled_time = downsample_signal(filtered_signal, original_freq)\n",
    "            # standardized_signal = clean_and_standardize(downsampled_signal)\n",
    "            standardized_signal = preprocess_ppg(ppg_signal)\n",
    "\n",
    "            df = pd.DataFrame(standardized_signal)\n",
    "            # df = pd.DataFrame({'Time': downsampled_time, 'Pleth': standardized_signal})\n",
    "            \n",
    "            output_file = os.path.join(output_dir, f'{basename}.txt')\n",
    "            df.to_csv(output_file, index=False, sep='\\t', header=None)\n",
    "\n",
    "            # print(f'File {basename} converted successfully.')\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'Error converting file {basename}: {e}.')\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "941afbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting EDF to TXT: 100%|██████████| 2055/2055 [1:41:20<00:00,  2.96s/it]\n"
     ]
    }
   ],
   "source": [
    "input_dir = '/run/media/u2212061/DISK_YUAN/913/mesa/polysomnography/edfs/'\n",
    "output_dir = '/run/media/u2212061/DISK_YUAN/913/mesa/polysomnography/ppg_34/'\n",
    "\n",
    "convert_edf_to_txt(input_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92abbf6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting EDF to TXT: 100%|██████████| 2055/2055 [2:25:37<00:00,  4.25s/it]  \n"
     ]
    }
   ],
   "source": [
    "input_dir = '/run/media/u2212061/DISK_YUAN/913/mesa/polysomnography/edfs/'\n",
    "output_dir = '/dcs/large/u2212061/raw_ppg_signal/'\n",
    "\n",
    "convert_edf_to_txt_no_header(input_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2023b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa629981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "728f1a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Read XML and tag the sleeping stages to the signals\n",
    "def parse_sleep_stages(input_dir, xml_filename):\n",
    "    xml_file = input_dir + xml_filename\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    scored_events = root.find('.//ScoredEvents')\n",
    "    if scored_events is None:\n",
    "        print(\"ScoredEvents not found\")\n",
    "        return None\n",
    "\n",
    "    sleep_stages = []\n",
    "\n",
    "    for event in scored_events.iter('ScoredEvent'):\n",
    "        event_type_element = event.find('EventType')\n",
    "        event_type = event_type_element.text if event_type_element is not None else None\n",
    "\n",
    "        if event_type == 'Stages|Stages':\n",
    "            event_concept = event.find('EventConcept').text\n",
    "            \n",
    "            start_time = float(event.find('Start').text)\n",
    "\n",
    "            duration = float(event.find('Duration').text)\n",
    "\n",
    "            if 'Wake' in event_concept:\n",
    "                stage = 0\n",
    "            elif 'Stage 1 sleep' in event_concept or 'Stage 2 sleep' in event_concept:\n",
    "                stage = 1\n",
    "            elif 'Stage 3 sleep' in event_concept or 'Stage 4 sleep' in event_concept:\n",
    "                stage = 2\n",
    "            elif 'REM sleep' in event_concept:\n",
    "                stage = 3\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            sleep_stages.append({'Start': start_time, \n",
    "                                'Duration': duration, \n",
    "                                'Stage': stage})\n",
    "\n",
    "    df_stage = pd.DataFrame(sleep_stages)\n",
    "\n",
    "    return df_stage\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f99c78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml_to_txt_file(output_dir, xml_filename, df_stage):\n",
    "    basename = xml_filename.split('.')[0]\n",
    "    parts = basename.split('-')\n",
    "    txt_filename = '-'.join(parts[:3]) + '.txt'\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    df_stage.to_csv(output_dir + txt_filename, sep='\\t', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c075378d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_xml_to_txt(input_dir, output_dir):\n",
    "    xml_files = [file for file in os.listdir(input_dir) if file.endswith('.xml')]\n",
    "\n",
    "    for xml_file in tqdm(xml_files, desc='Processing XML files'):\n",
    "        xml_filename = xml_file\n",
    "        df_stage = parse_sleep_stages(input_dir, xml_filename)\n",
    "            \n",
    "        xml_to_txt_file(output_dir, xml_filename, df_stage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed4b95d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing XML files: 100%|██████████| 2056/2056 [03:47<00:00,  9.05it/s]\n"
     ]
    }
   ],
   "source": [
    "input_dir = '/run/media/u2212061/DISK_YUAN/CS913/mesa/polysomnography/annotations-events-nsrr/'\n",
    "output_dir = '/run/media/u2212061/DISK_YUAN/CS913/mesa/polysomnography/xml_txt/'\n",
    "\n",
    "convert_xml_to_txt(input_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "424cb903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_labels_to_30s_window(input_dir, output_dir):\n",
    "\n",
    "    for txt_file in tqdm(os.listdir(input_dir), desc='Expanding labels to 30s window'):\n",
    "        df_xml = pd.read_csv(os.path.join(input_dir, txt_file), sep='\\t')\n",
    "        df_xml = pd.DataFrame(df_xml)\n",
    "\n",
    "        total_time = df_xml['Start'].iloc[-1] + df_xml['Duration'].iloc[-1]\n",
    "        num_segments = int(np.ceil(total_time / 30.0))\n",
    "\n",
    "        labels = np.zeros(num_segments, dtype=int)\n",
    "\n",
    "        for i, row in df_xml.iterrows():\n",
    "            start_idx = int(row['Start'] // 30)\n",
    "            end_idx = int((row['Start'] + row['Duration']) // 30)\n",
    "\n",
    "            if end_idx > len(labels):\n",
    "                end_idx = len(labels)\n",
    "            \n",
    "            labels[start_idx:end_idx] = row['Stage']\n",
    "        \n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        \n",
    "        # df_stage = pd.DataFrame({'Stage': labels})\n",
    "        df_stage = pd.DataFrame(labels)\n",
    "        df_stage.to_csv(output_dir + txt_file, sep='\\t', index=False, header=None)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d98fa4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expanding labels to 30s window: 100%|██████████| 2056/2056 [02:31<00:00, 13.58it/s]\n"
     ]
    }
   ],
   "source": [
    "input_dir = '/run/media/u2212061/DISK_YUAN/913/mesa/polysomnography/xml_txt/'\n",
    "output_dir = '/dcs/large/u2212061/raw_stage_ann/'\n",
    "\n",
    "expand_labels_to_30s_window(input_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a50a41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding zero and truncating to 1228800 for signal data \n",
    "\n",
    "def padding_and_truncating_signal_data(input_dir, output_dir, target_length):\n",
    "    for txt_file in tqdm(os.listdir(input_dir), desc='Padding and Truncating to 10 hours'):\n",
    "        # df_ppg = pd.read_csv(os.path.join(input_dir, txt_file), sep='\\t')\n",
    "        df_ppg = np.loadtxt(os.path.join(input_dir, txt_file), dtype='float')\n",
    "\n",
    "        current_length = len(df_ppg)\n",
    "\n",
    "        if target_length <= current_length:\n",
    "            # df_ppg = df_ppg.iloc[:target_length]\n",
    "            df_ppg = df_ppg[:target_length]\n",
    "        else:\n",
    "            padding_length = target_length - current_length\n",
    "            # padding = np.zeros((padding_length, df_ppg.shape[1]))\n",
    "            padding = np.zeros(padding_length)\n",
    "            # df_ppg = pd.concat([df_ppg, pd.DataFrame(padding)], ignore_index=True)\n",
    "            df_ppg = np.concatenate([df_ppg, padding])\n",
    "        \n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        \n",
    "        # df_ppg.to_csv(output_dir + txt_file, sep='\\t', index=False, header=None)\n",
    "        np.savetxt(output_dir + txt_file, df_ppg, fmt='%.18f')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "838d0663",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Padding and Truncating to 10 hours: 100%|██████████| 2055/2055 [1:08:57<00:00,  2.01s/it]\n"
     ]
    }
   ],
   "source": [
    "input_dir = '/run/media/u2212061/DISK_YUAN/913/mesa/polysomnography/ppg_34/'\n",
    "output_dir = '/dcs/large/u2212061/ppg_34_zero/'\n",
    "target_length = 1228800\n",
    "\n",
    "padding_and_truncating_signal_data(input_dir, output_dir, target_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "226f6855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding -1 and truncating to 1200 for labels (stages)\n",
    "def padding_and_truncating_stage_data(input_dir, output_dir, match_dir, target_length):\n",
    "    for txt_file in tqdm(os.listdir(input_dir), desc='Padding and Truncating to 10 hours'):\n",
    "        if txt_file in os.listdir(match_dir):\n",
    "\n",
    "            # df_stage = pd.read_csv(os.path.join(input_dir, txt_file), sep='\\t')\n",
    "            df_stage = np.loadtxt(os.path.join(input_dir, txt_file), dtype='int')\n",
    "\n",
    "            current_length = len(df_stage)\n",
    "\n",
    "            if target_length <= current_length:\n",
    "                # df_stage = df_stage.iloc[:target_length]\n",
    "                df_stage = df_stage[:target_length]\n",
    "            else:\n",
    "                padding_length = target_length - current_length\n",
    "                # Padding with -1\n",
    "                # padding = np.full((padding_length, df_stage.shape[1]), int(-1))\n",
    "                padding = np.full(padding_length, int(-1))\n",
    "                # df_stage = pd.concat([df_stage, pd.DataFrame(padding)], ignore_index=True)\n",
    "                df_stage = np.concatenate([df_stage, padding])\n",
    "\n",
    "                \n",
    "            if not os.path.exists(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "                \n",
    "            # df_stage.to_csv(output_dir + txt_file, sep='\\t', index=False, header=None)\n",
    "            np.savetxt(output_dir + txt_file, df_stage, fmt='%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fe1af907",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Padding and Truncating to 10 hours: 100%|██████████| 2056/2056 [06:35<00:00,  5.20it/s]\n"
     ]
    }
   ],
   "source": [
    "input_dir = '/run/media/u2212061/DISK_YUAN/CS913/mesa/polysomnography/xml_30_stage/'\n",
    "output_dir = '/run/media/u2212061/DISK_YUAN/CS913/mesa/polysomnography/stage_30_minus/'\n",
    "match_dir = '/run/media/u2212061/DISK_YUAN/CS913/mesa/polysomnography/ppg_34_zero/'\n",
    "target_length = 1200\n",
    "\n",
    "padding_and_truncating_stage_data(input_dir, output_dir, match_dir, target_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "21e06dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "df_stage = pd.read_csv('/run/media/u2212061/DISK_YUAN/CS913/mesa/polysomnography/stage_30_minus/mesa-sleep-0006.txt', header=None)\n",
    "\n",
    "print(len(df_stage))\n",
    "print(type(df_stage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aaf1fd1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "np_stage = np.loadtxt('/run/media/u2212061/DISK_YUAN/CS913/mesa/polysomnography/stage_30_minus/mesa-sleep-0006.txt')\n",
    "\n",
    "print(len(np_stage))\n",
    "print(type(np_stage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bdad1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.1+cu121\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d786dc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [14:14<00:00,  2.40it/s]\n"
     ]
    }
   ],
   "source": [
    "def check_empty_or_na_entries(input_dir):\n",
    "    for csv_file in tqdm(os.listdir(input_dir), desc='Checking for empty entries'):\n",
    "\n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(os.path.join(input_dir, csv_file), sep='\\t')\n",
    "        \n",
    "        # Check for empty entries (NaNs)\n",
    "        empty_entries = df.isna().sum().sum()\n",
    "        \n",
    "        # Check for rows with all NA entries\n",
    "        rows_all_na = df.isna().all(axis=1).sum()\n",
    "        \n",
    "        # Check for columns with all NA entries\n",
    "        cols_all_na = df.isna().all(axis=0).sum()\n",
    "        \n",
    "        if empty_entries != 0 or rows_all_na != 0 or cols_all_na != 0:\n",
    "            print(f'File: {csv_file}:')\n",
    "            print(f'Total empty entries: {empty_entries}')\n",
    "            print(f'Rows with all NA entries: {rows_all_na}')\n",
    "            print(f'Columns with all NA entries: {cols_all_na}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df08307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228b7669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45401b730fc2ed9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T15:56:16.217654Z",
     "start_time": "2024-04-26T15:55:39.006605Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c3b22f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0db63cb38443bd7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # For mac\n",
    "# input_dir = '/Users/zhaojingyuan/Desktop/CS913/mesa/polysomnography/edfs'\n",
    "# output_dir = \"/Users/zhaojingyuan/Desktop/CS913/mesa/polysomnography/edfs_ppg_txt\"\n",
    "\n",
    "# convert_edf_to_txt(input_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c4de99274f7cb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T15:56:17.667325Z",
     "start_time": "2024-04-26T15:56:16.219029Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "595d3c1cd372bbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T15:56:17.669615Z",
     "start_time": "2024-04-26T15:56:17.668361Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
